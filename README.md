# Embodied AI (具身智能) ![](https://visitor-badge.glitch.me/badge?page_id=putao537.Awesome-Embodied-AI)

<h4 align="center">Everything about Embodied AI.</h4>

<p align="center">
  <strong><a href="#0">Papers</a></strong> •
  <strong><a href="#1">Tutorials</a></strong> •
  <strong><a href="#2">Workshops</a></strong> •
  <strong><a href="#3">Talks</a></strong> •
  <strong><a href="#4">Scholars & Teams</a></strong>
</p>

<p align="center">
  <strong><a href="#5">Surveys</a></strong> •
  <strong><a href="#6">Tasks</a></strong> •
  <strong><a href="#7">Virtual Environments</a></strong> •
  <strong><a href="#8">Datasets & Benchmarks</a></strong>
</p>


<h2 id="0">0. Papers</h2>

**By Date:** [[2022]](Papers/2022.md) [[2021]](Papers/2021.md) [[2020]](Papers/2020.md) [[2019]](Papers/2019.md) [[2018]](Papers/2018.md)    
**By Tasks:** [[Locomotion]](Papers/locomotion.md) [[Visual Navigation]](Papers/visual_navigation.md) [[Object Manipulation]](Papers/object_manipulation.md) [[Rearrangement]](Papers/rearrangement.md)

<h2 id="1">1. Tutorials</h2>

|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| **CVPR'22** | Building and Working in Environments for Embodied AI | [HomePage](https://ai-workshops.github.io/building-and-working-in-environments-for-embodied-ai-cvpr-2022/) |


<h2 id="2">2. Workshops</h2>

|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| **CVPR'22** | Embodied AI Workshop | [HomePage](https://embodied-ai.org/) |
| **CVPR'21** | Embodied AI Workshop | [HomePage](https://embodied-ai.org/cvpr2021) |
| **ICCV'21** | SEAI: Simulation Technology for Embodied AI | [HomePage](https://iccv21-seai.github.io/) |
| **CVPR'20** | Embodied AI Workshop | [HomePage](https://embodied-ai.org/cvpr2020) |


<h2 id="3">3. Talks</h2>

<details>
  <summary> xxx </summary>
  
  ### 2022
|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| **TPAMI** | **[xxx]** xxxx | [PDF](xxx) |

</details>


<h2 id="4">4. Scholars & Labs</h2>

### Labs
- [Robotic Systems Lab](https://rsl.ethz.ch/), ETH Zurich
- [Stanford Vision And Learning Lab](https://svl.stanford.edu/), Standford


<h2 id="5">5. Surveys</h2>

|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| **T-ETCI'22* | A Survey of Embodied AI: From Simulators to Research Tasks | [PDF]([xxx](https://arxiv.org/abs/2103.04918)) |


<h2 id="6">6. Tasks</h2>

<details>
  <summary> Locomotion </summary>  

</details>

<details>
  <summary> Visual Navigation </summary>  

  - **REVERIE** (CVPR 2020, [[PDF]](https://arxiv.org/abs/1904.10151)) requires an intelligent agent to correctly localize a remote target object (can not be observed at starting location) specified by a concise high-level natural language instruction.
  
  - **TOUCHDOWN** (CVPR 2019, [[PDF]](https://arxiv.org/abs/1811.12354)) requires an agent to first follow navigation instructions in a real-life visual urban environment, and then identify a location described in natural language to find a hidden object at the goal position.

  - **VNLA** (CVPR 2019, [[PDF]](https://arxiv.org/abs/1812.04155)) requires an embodied agent to follow natural language instructions to navigate from a starting pose to a goal location. 
  
  - **VLN** (CVPR 2018, [[PDF]](https://arxiv.org/abs/1711.07280)) requires an embodied agent to follow natural language instructions to navigate from a starting pose to a goal location.  
  
  - **IQA** (CVPR 2018, [[PDF]](https://arxiv.org/abs/1712.03316)) puts an intelligent agent at random location in a 3D environment and asked a question. This task requires an agent to navigate around the scene, acquire visual understanding of scene elements, interact with objects (e.g. open refrigerators) and plan for a series of actions conditioned on the question.
   
  - **EQA** (CVPR 2018, [[PDF]](https://arxiv.org/abs/1711.11543)) puts an intelligent agent at random location in a 3D environment and asked a question. The agent must first intelligently navigate to explore the environment, gather necessary visual information through first-person (egocentric) vision, and then answer the question.

</details>


<details>
  <summary> Object Manipulation </summary>  


</details>


<details>
  <summary> Rearrangement </summary>  


</details>

<h2 id="7">7. Virtual Environments</h2>

<details>
  <summary> AI2-THOR [![](https://img.shields.io/badge/link-AI2THOR-red.svg)]([https://996.icu](https://ai2thor.allenai.org)) </summary>
 
Related Papers:
  - AI2-THOR: An Interactive 3D Environment for Visual AI, arxiv'17, [[PDF]](https://arxiv.org/pdf/1712.05474.pdf)
  - RoboTHOR: An Open Simulation-to-Real Embodied AI Platform, CVPR'20, [[PDF]](https://arxiv.org/pdf/2004.06799.pdf)
  - ManipulaTHOR: A Framework for Visual Object Manipulation, CVPR'21, [[PDF]](https://arxiv.org/pdf/2104.11213.pdf)
  - ProcTHOR: Large-Scale Embodied AI Using Procedural Generation, arxiv'22, [[PDF]](https://arxiv.org/pdf/2206.06994.pdf)
  
</details>

- AI2-THOR ([[Project]](https://ai2thor.allenai.org/))  
  - AI2-THOR: An Interactive 3D Environment for Visual AI, arxiv'17, [[PDF]](https://arxiv.org/pdf/1712.05474.pdf)
  - RoboTHOR: An Open Simulation-to-Real Embodied AI Platform, CVPR'20, [[PDF]](https://arxiv.org/pdf/2004.06799.pdf)
  - ManipulaTHOR: A Framework for Visual Object Manipulation, CVPR'21, [[PDF]](https://arxiv.org/pdf/2104.11213.pdf)
  - ProcTHOR: Large-Scale Embodied AI Using Procedural Generation, arxiv'22, [[PDF]](https://arxiv.org/pdf/2206.06994.pdf)

- AI Habitat ([[Project]](https://aihabitat.org/))  
  - Habitat: A Platform for Embodied AI Research, ICCV'19, [[PDF]](https://arxiv.org/pdf/1904.01201.pdf)
  - Habitat 2.0: Training Home Assistants to Rearrange their Habitat, NeurIPS'21, [[PDF]](https://arxiv.org/abs/2106.14405.pdf)

- VirtualHome ([[Project]](http://virtual-home.org/))     
  - VirtualHome: Simulating Household Activities via Programs, CVPR'18, [[PDF]](https://arxiv.org/pdf/1806.07011.pdf)

- House3D ([[Project]](https://github.com/facebookresearch/House3D))  
  - Building generalizable agents with a realistic and rich 3D environment, arxiv'18, [[PDF]](https://arxiv.org/pdf/1801.02209.pdf)

- Gibson ([[Project]](http://gibsonenv.stanford.edu/))  
  - Gibson Env: Real-World Perception for Embodied Agents, arxiv'18, [[PDF]](https://arxiv.org/pdf/1808.10654.pdf)

- Matterport3D ([[Project]](https://niessner.github.io/Matterport/))  
  - Matterport3D: Learning from RGB-D Data in Indoor Environments, 3DV'17, [[PDF]](https://arxiv.org/pdf/1709.06158.pdf)

- UnrealCV ([[Project]](https://unrealcv.org/))
  - UnrealCV: Virtual Worlds for Computer Vision, ACM MM'17, [[PDF]](https://dl.acm.org/doi/pdf/10.1145/3123266.3129396)
  
- CHALET ([[Project]](https://github.com/lil-lab/chalet))
  - CHALET: Cornell House Agent Learning Environment, arxiv'18, [[PDF]](https://arxiv.org/pdf/1801.07357.pdf)

- ALFWorld ([[Project]](https://alfworld.github.io/))
  - ALFWorld: Aligning Text and Embodied Environments for Interactive Learning, ICLR'21, [[PDF]](https://arxiv.org/pdf/2010.03768.pdf)

<h2 id="8">8. Datasets & Benchmarks</h2>

<details>
  <summary> xxx </summary>
  
  ### 2022
|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| **TPAMI** | **[xxx]** xxxx | [PDF](xxx) |

</details>
