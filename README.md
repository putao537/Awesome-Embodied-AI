# Embodied AI (具身智能) ![](https://visitor-badge.glitch.me/badge?page_id=putao537.Awesome-Embodied-AI)

<h4 align="center">Everything about Embodied AI.</h4>

<p align="center">
  <strong><a href="#0">Papers</a></strong> •
  <strong><a href="#1">Tutorials</a></strong> •
  <strong><a href="#2">Workshops</a></strong> •
  <strong><a href="#3">Talks</a></strong> •
  <strong><a href="#4">Scholars & Teams</a></strong>
</p>

<p align="center">
  <strong><a href="#5">Surveys</a></strong> •
  <strong><a href="#6">Tasks</a></strong> •
  <strong><a href="#7">Virtual Environments</a></strong> •
  <strong><a href="#8">Datasets & Benchmarks</a></strong>
</p>


<h2 id="0">0. Papers</h2>

**By Date:** [[2022]](Papers/2022.md) [[2021]](Papers/2021.md) [[2020]](Papers/2020.md) [[2019]](Papers/2019.md) [[2018]](Papers/2018.md)    
**By Tasks:** [[Locomotion]](Papers/locomotion.md) [[Visual Navigation]](Papers/visual_navigation.md) [[Object Manipulation]](Papers/object_manipulation.md) [[Rearrangement]](Papers/rearrangement.md)

<h2 id="1">1. Tutorials</h2>

|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| **CVPR'22** | Building and Working in Environments for Embodied AI | [HomePage](https://ai-workshops.github.io/building-and-working-in-environments-for-embodied-ai-cvpr-2022/) |


<h2 id="2">2. Workshops</h2>

|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| **CVPR'22** | Embodied AI Workshop | [HomePage](https://embodied-ai.org/) |
| **CVPR'21** | Embodied AI Workshop | [HomePage](https://embodied-ai.org/cvpr2021) |
| **ICCV'21** | SEAI: Simulation Technology for Embodied AI | [HomePage](https://iccv21-seai.github.io/) |
| **CVPR'20** | Embodied AI Workshop | [HomePage](https://embodied-ai.org/cvpr2020) |


<h2 id="3">3. Talks</h2>

<details>
  <summary> xxx </summary>
  
  ### 2022
|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| **TPAMI** | **[xxx]** xxxx | [PDF](xxx) |

</details>


<h2 id="4">4. Scholars & Labs</h2>

### Labs
- [Robotic Systems Lab](https://rsl.ethz.ch/), ETH Zurich
- [Stanford Vision And Learning Lab](https://svl.stanford.edu/), Standford


<h2 id="5">5. Surveys</h2>

|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| **T-ETCI'22* | A Survey of Embodied AI: From Simulators to Research Tasks | [PDF]([xxx](https://arxiv.org/abs/2103.04918)) |


<h2 id="6">6. Tasks</h2>

<details>
  <summary> Locomotion </summary>  

</details>

<details>
  <summary> Visual Navigation </summary>  

  - **REVERIE** (CVPR 2020, [[PDF]](https://arxiv.org/abs/1904.10151)) requires an intelligent agent to correctly localize a remote target object (can not be observed at starting location) specified by a concise high-level natural language instruction.
  
  - **TOUCHDOWN** (CVPR 2019, [[PDF]](https://arxiv.org/abs/1811.12354)) requires an agent to first follow navigation instructions in a real-life visual urban environment, and then identify a location described in natural language to find a hidden object at the goal position.

  - **VNLA** (CVPR 2019, [[PDF]](https://arxiv.org/abs/1812.04155)) requires an embodied agent to follow natural language instructions to navigate from a starting pose to a goal location. 
  
  - **VLN** (CVPR 2018, [[PDF]](https://arxiv.org/abs/1711.07280)) requires an embodied agent to follow natural language instructions to navigate from a starting pose to a goal location.  
  
  - **IQA** (CVPR 2018, [[PDF]](https://arxiv.org/abs/1712.03316)) puts an intelligent agent at random location in a 3D environment and asked a question. This task requires an agent to navigate around the scene, acquire visual understanding of scene elements, interact with objects (e.g. open refrigerators) and plan for a series of actions conditioned on the question.
   
  - **EQA** (CVPR 2018, [[PDF]](https://arxiv.org/abs/1711.11543)) puts an intelligent agent at random location in a 3D environment and asked a question. The agent must first intelligently navigate to explore the environment, gather necessary visual information through first-person (egocentric) vision, and then answer the question.

</details>


<details>
  <summary> Object Manipulation </summary>  


</details>


<details>
  <summary> Rearrangement </summary>  


</details>

<h2 id="7">7. Virtual Environments</h2>

- [AI2-THOR](https://img.shields.io/badge/link-AI2THOR-red.svg)      
  <details>
    <summary> Related Papers </summary>
  
      - AI2-THOR: An Interactive 3D Environment for Visual AI, arxiv'17
      - RoboTHOR: An Open Simulation-to-Real Embodied AI Platform, CVPR'20
      - ManipulaTHOR: A Framework for Visual Object Manipulation, CVPR'21
      - ProcTHOR: Large-Scale Embodied AI Using Procedural Generation, arxiv'22
  
  </details>

- [AI Habitat](https://aihabitat.org/)  
  <details>
    <summary> Related Papers </summary>
  
      - Habitat: A Platform for Embodied AI Research, ICCV'19, [[PDF]](https://arxiv.org/pdf/1904.01201.pdf)
      - Habitat 2.0: Training Home Assistants to Rearrange their Habitat, NeurIPS'21
  
  </details>
  
- [VirtualHome](http://virtual-home.org/)     
  <details>
    <summary> Related Papers </summary>
  
      - VirtualHome: Simulating Household Activities via Programs, CVPR'18
  
  </details>
  
- [House3D](https://github.com/facebookresearch/House3D)   
  <details>
    <summary> Related Papers </summary>
  
      - Building generalizable agents with a realistic and rich 3D environment, arxiv'18
  
  </details>
  
- [Gibson](http://gibsonenv.stanford.edu/)  
  <details>
    <summary> Related Papers </summary>
  
      - Gibson Env: Real-World Perception for Embodied Agents, arxiv'18
  
  </details>
  
- [Matterport3D](https://niessner.github.io/Matterport/)   
  <details>
    <summary> Related Papers </summary>
  
      - Matterport3D: Learning from RGB-D Data in Indoor Environments, 3DV'17
  
  </details>
  
- [UnrealCV](https://unrealcv.org/)  
  <details>
    <summary> Related Papers </summary>
  
      - UnrealCV: Virtual Worlds for Computer Vision, ACM MM'17
  
  </details>
  
- [CHALET](https://github.com/lil-lab/chalet)   
  <details>
    <summary> Related Papers </summary>
  
      - CHALET: Cornell House Agent Learning Environment, arxiv'18
  
  </details>
  
- [ALFWorld](https://alfworld.github.io/)   
  <details>
    <summary> Related Papers </summary>
  
      - ALFWorld: Aligning Text and Embodied Environments for Interactive Learning, ICLR'21
  
  </details>
<h2 id="8">8. Datasets & Benchmarks</h2>

<details>
  <summary> xxx </summary>
  
  ### 2022
|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| **TPAMI** | **[xxx]** xxxx | [PDF](xxx) |

</details>
